#youtube.py (Fast Join + Video/Audio Fix)
import asyncio
import os
import re
import json
from typing import Union

import yt_dlp
import requests  # <-- Error 1: á€™á€™á€¼á€„á€ºá€›á€á€²á€· space á€€á€­á€¯ á€–á€šá€ºá€›á€¾á€¬á€¸á€‘á€¬á€¸á€á€Šá€º
from pyrogram.enums import MessageEntityType
from pyrogram.types import Message
from youtubesearchpython.__future__ import VideosSearch

# --- (youtubedatabase.py á€€á€­á€¯ á€á€®á€¸á€á€”á€·á€º import á€œá€¯á€•á€ºá€•á€«) ---
# --- (get_all_yt_cache function á€¡á€á€…á€ºá€€á€­á€¯á€•á€« import á€œá€¯á€•á€ºá€•á€«) ---
try:
    from maythusharmusic.utils.database.youtubedatabase import (
        is_on_off,
        get_yt_cache,
        save_yt_cache,
        get_cached_song_path,
        save_cached_song_path,
        remove_cached_song_path,
        get_all_yt_cache  # <-- Error 2: á€€á€»á€”á€ºá€”á€±á€á€¬á€€á€­á€¯ á€‘á€•á€ºá€–á€¼á€Šá€·á€ºá€‘á€¬á€¸á€á€Šá€º
    )
except ImportError:
    print("FATAL ERROR: youtubedatabase.py á€€á€­á€¯ á€›á€¾á€¬á€™á€á€½á€±á€·á€•á€«")
    # á€’á€®á€”á€±á€›á€¬á€™á€¾á€¬ bot á€€á€­á€¯ á€›á€•á€ºá€á€„á€·á€ºá€›á€„á€º á€›á€•á€ºá€”á€­á€¯á€„á€ºá€•á€«á€á€šá€º
    raise
# --- (á€’á€®á€”á€±á€›á€¬á€¡á€‘á€­) ---
from maythusharmusic.utils.formatters import time_to_seconds

import os
import glob
import random
import logging
import aiohttp 

# Logger á€€á€­á€¯ á€á€á€ºá€™á€¾á€á€ºá€á€¼á€„á€ºá€¸
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)



API_URL = "https://teaminflex.xyz"  # Change to your API server URL
API_KEY = "INFLEX93454428D"

# ==============================================
# ğŸµ AUDIO DOWNLOAD
# ==============================================
async def download_song(link: str) -> str:
    video_id = link.split('v=')[-1].split('&')[0] if 'v=' in link else link
    logger = LOGGER("InflexMusic/platforms/Youtube.py")
    logger.info(f"ğŸµ [AUDIO] Starting download process for ID: {video_id}")

    if not video_id or len(video_id) < 3:
        return

    DOWNLOAD_DIR = "downloads"
    os.makedirs(DOWNLOAD_DIR, exist_ok=True)
    file_path = os.path.join(DOWNLOAD_DIR, f"{video_id}.webm")

    if os.path.exists(file_path):
        logger.info(f"ğŸµ [LOCAL] Found existing file for ID: {video_id}")
        return file_path

    try:
        async with aiohttp.ClientSession() as session:
            payload = {"url": video_id, "type": "audio"}
            headers = {
                "Content-Type": "application/json",
                "X-API-KEY": API_KEY
            }

            # ğŸ”¹ Step 1: Trigger API and wait until it's ready (API handles waiting)
            async with session.post(f"{API_URL}/download", json=payload, headers=headers) as response:
                if response.status == 401:
                    logger.error("[API] Invalid API key")
                    return
                if response.status != 200:
                    logger.error(f"[AUDIO] API returned {response.status}")
                    return

                data = await response.json()
                if data.get("status") != "success" or not data.get("download_url"):
                    logger.error(f"[AUDIO] API response error: {data}")
                    return

                download_link = f"{API_URL}{data['download_url']}"

            # ğŸ”¹ Step 2: Download file (file is ready now)
            async with session.get(download_link) as file_response:
                if file_response.status != 200:
                    logger.error(f"[AUDIO] Download failed ({file_response.status}) for ID: {video_id}")
                    return
                with open(file_path, "wb") as f:
                    async for chunk in file_response.content.iter_chunked(8192):
                        f.write(chunk)

        logger.info(f"ğŸµ [API] Download completed successfully for ID: {video_id}")
        return file_path

    except Exception as e:
        logger.error(f"[AUDIO] Exception for ID: {video_id} - {e}")
        return


# ==============================================
# ğŸ¥ VIDEO DOWNLOAD
# ==============================================
async def download_video(link: str) -> str:
    video_id = link.split('v=')[-1].split('&')[0] if 'v=' in link else link
    logger = LOGGER("InflexMusic/platforms/Youtube.py")
    logger.info(f"ğŸ¥ [VIDEO] Starting download process for ID: {video_id}")

    if not video_id or len(video_id) < 3:
        return

    DOWNLOAD_DIR = "downloads"
    os.makedirs(DOWNLOAD_DIR, exist_ok=True)
    file_path = os.path.join(DOWNLOAD_DIR, f"{video_id}.mkv")

    if os.path.exists(file_path):
        logger.info(f"ğŸ¥ [LOCAL] Found existing file for ID: {video_id}")
        return file_path

    try:
        async with aiohttp.ClientSession() as session:
            payload = {"url": video_id, "type": "video"}
            headers = {
                "Content-Type": "application/json",
                "X-API-KEY": API_KEY
            }

            # ğŸ”¹ Step 1: Trigger API (it waits internally until file is ready)
            async with session.post(f"{API_URL}/download", json=payload, headers=headers) as response:
                if response.status == 401:
                    logger.error("[API] Invalid API key")
                    return
                if response.status != 200:
                    logger.error(f"[VIDEO] API returned {response.status}")
                    return

                data = await response.json()
                if data.get("status") != "success" or not data.get("download_url"):
                    logger.error(f"[VIDEO] API response error: {data}")
                    return

                download_link = f"{API_URL}{data['download_url']}"

            # ğŸ”¹ Step 2: Download the ready file
            async with session.get(download_link) as file_response:
                if file_response.status != 200:
                    logger.error(f"[VIDEO] Download failed ({file_response.status}) for ID: {video_id}")
                    return
                with open(file_path, "wb") as f:
                    async for chunk in file_response.content.iter_chunked(8192):
                        f.write(chunk)

        logger.info(f"ğŸ¥ [API] Download completed successfully for ID: {video_id}")
        return file_path

    except Exception as e:
        logger.error(f"[VIDEO] Exception for ID: {video_id} - {e}")
        return

def get_cookies():
    """
    á€á€á€ºá€™á€¾á€á€ºá€‘á€¬á€¸á€á€±á€¬ cookies.txt á€–á€­á€¯á€„á€ºá path á€€á€­á€¯ á€•á€¼á€”á€ºá€•á€±á€¸á€á€Šá€ºá‹
    """
    global _cookies_warned
    cookie_path = "maythusharmusic/cookies/cookies.txt"
    
    if not os.path.exists(cookie_path):
        if not _cookies_warned:
            _cookies_warned = True
            logger.warning(f"{cookie_path} á€€á€­á€¯ á€›á€¾á€¬á€™á€á€½á€±á€·á€•á€«áŠ download á€™á€»á€¬á€¸ á€™á€¡á€±á€¬á€„á€ºá€™á€¼á€„á€ºá€”á€­á€¯á€„á€ºá€•á€«á‹")
        return None
        
    return cookie_path

async def save_cookies(urls: list[str]) -> None:
    """
    á€•á€±á€¸á€œá€¬á€á€±á€¬ URL á€™á€»á€¬á€¸á€‘á€²á€™á€¾ á€•á€‘á€™á€†á€¯á€¶á€¸ URL á€™á€¾ cookie á€€á€­á€¯ cookies.txt á€á€½á€„á€º á€á€­á€™á€ºá€¸á€†á€Šá€ºá€¸á€á€Šá€ºá‹
    """
    if not urls:
        logger.warning("save_cookies á€á€­á€¯á€· URL á€™á€»á€¬á€¸ á€•á€±á€¸á€•á€­á€¯á€·á€™á€‘á€¬á€¸á€•á€«á‹")
        return
    
    logger.info("á€•á€‘á€™á€†á€¯á€¶á€¸ URL á€™á€¾ cookie á€€á€­á€¯ cookies.txt á€á€½á€„á€º á€á€­á€™á€ºá€¸á€†á€Šá€ºá€¸á€”á€±á€•á€«á€á€Šá€º...")
    url = urls[0]  # á€•á€‘á€™á€†á€¯á€¶á€¸ URL á€€á€­á€¯á€á€¬ á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€™á€Šá€º
    path = "maythusharmusic/cookies/cookies.txt"
    link = url.replace("me/", "me/raw/")
    
    # Cookie á€á€­á€™á€ºá€¸á€†á€Šá€ºá€¸á€™á€Šá€·á€º directory á€›á€¾á€­á€™á€›á€¾á€­ á€…á€…á€ºá€†á€±á€¸á€•á€¼á€®á€¸ á€™á€›á€¾á€­á€•á€«á€€ á€á€Šá€ºá€†á€±á€¬á€€á€ºá€á€Šá€º
    os.makedirs(os.path.dirname(path), exist_ok=True)
        
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(link) as resp:
                if resp.status == 200:
                    with open(path, "wb") as fw:
                        fw.write(await resp.read())
                    logger.info("Cookie á€™á€»á€¬á€¸á€€á€­á€¯ cookies.txt á€á€½á€„á€º á€¡á€±á€¬á€„á€ºá€™á€¼á€„á€ºá€…á€½á€¬ á€á€­á€™á€ºá€¸á€†á€Šá€ºá€¸á€•á€¼á€®á€¸á€•á€«á€•á€¼á€®á‹")
                else:
                    logger.error(f"{link} á€™á€¾ cookie download á€œá€¯á€•á€ºá€›á€¬á€á€½á€„á€º á€™á€¡á€±á€¬á€„á€ºá€™á€¼á€„á€ºá€•á€«áŠ status: {resp.status}")
    except Exception as e:
        logger.error(f"Cookie á€á€­á€™á€ºá€¸á€†á€Šá€ºá€¸á€›á€¬á€á€½á€„á€º á€¡á€™á€¾á€¬á€¸á€¡á€šá€½á€„á€ºá€¸ á€–á€¼á€…á€ºá€•á€½á€¬á€¸á€•á€«á€á€Šá€º: {e}")


async def check_file_size(link):
    async def get_format_info(link):
        
        # --- Cookie Logic ---
        # 1. (á€’á€® file á€‘á€²á€™á€¾á€¬ á€›á€¾á€­á€•á€¼á€®á€¸á€á€¬á€¸) get_cookies() function á€€á€­á€¯ á€á€±á€«á€ºá€á€¯á€¶á€¸á€•á€«
        cookie_file = get_cookies() 
        
        # 2. Command arguments á€á€½á€±á€€á€­á€¯ list á€¡á€”á€±á€”á€²á€· á€á€Šá€ºá€†á€±á€¬á€€á€ºá€•á€«
        proc_args = [
            "yt-dlp",
            "-J", # JSON output
        ]
        
        # 3. Cookie file á€›á€¾á€­á€á€²á€·á€›á€„á€º command á€‘á€²á€€á€­á€¯ á€‘á€Šá€·á€ºá€•á€«
        if cookie_file:
            proc_args.extend(["--cookies", cookie_file])
        
        # 4. á€”á€±á€¬á€€á€ºá€†á€¯á€¶á€¸á€™á€¾á€¬ link á€€á€­á€¯ á€‘á€Šá€·á€ºá€•á€«
        proc_args.append(link)
        # --- End Cookie Logic ---

        proc = await asyncio.create_subprocess_exec(
            *proc_args,  # List á€€á€­á€¯ unpack á€œá€¯á€•á€ºá€•á€¼á€®á€¸ á€‘á€Šá€·á€ºá€•á€«
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        stdout, stderr = await proc.communicate()
        if proc.returncode != 0:
            print(f'Error:\n{stderr.decode()}')
            return None
        return json.loads(stdout.decode())

    def parse_size(formats):
        total_size = 0
        for format in formats:
            if 'filesize' in format:
                total_size += format['filesize']
        return total_size

    info = await get_format_info(link)
    if info is None:
        return None
    
    formats = info.get('formats', [])
    if not formats:
        print("No formats found.")
        return None
    
    total_size = parse_size(formats)
    return total_size


async def shell_cmd(cmd):
    proc = await asyncio.create_subprocess_shell(
        cmd,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE,
    )
    out, errorz = await proc.communicate()
    if errorz:
        if "unavailable videos are hidden" in (errorz.decode("utf-8")).lower():
            return out.decode("utf-8")
        else:
            return errorz.decode("utf-8")
    return out.decode("utf-8")


class YouTubeAPI:
    def __init__(self):
        self.base = "https://www.youtube.com/watch?v="
        self.regex = r"(?:youtube\.com|youtu\.be)"
        self.status = "https://www.youtube.com/oembed?url="
        self.listbase = "https://youtube.com/playlist?list="
        self.reg = re.compile(r"\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])")
        
        # --- Caching á€¡á€á€½á€€á€º Dictionary (Bot run á€á€»á€­á€”á€ºá€™á€¾á€¬ á€¡á€œá€½á€á€ºá€–á€¼á€…á€ºá€”á€±á€•á€«á€™á€šá€º) ---
        self._search_cache = {}

    # --- (FUNCTION á€¡á€á€…á€º - Bot Startup á€á€½á€„á€º á€á€±á€«á€ºá€›á€”á€º) ---
    async def load_cache(self):
        """
        Bot startup á€á€½á€„á€º MongoDB á€™á€¾ cache á€™á€»á€¬á€¸á€€á€­á€¯ á€šá€¬á€šá€®á€™á€¾á€á€ºá€‰á€¬á€á€ºá€‘á€²á€á€­á€¯á€· á€€á€¼á€­á€¯á€á€„á€ºá€–á€¼á€Šá€·á€ºá€á€Šá€º
        (Hydrates the in-memory cache from permanent DB on startup)
        """
        logger.info("MongoDB á€™á€¾ YouTube search cache á€™á€»á€¬á€¸á€€á€­á€¯ á€€á€¼á€­á€¯á€á€„á€ºá€–á€¼á€Šá€·á€ºá€”á€±á€•á€«á€á€Šá€º...")
        try:
            # youtubedatabase.py á€‘á€²á€€ function á€¡á€á€…á€ºá€€á€­á€¯ á€á€±á€«á€ºá€•á€«
            all_cache = await get_all_yt_cache() 
            if all_cache:
                # DB á€€á€›á€œá€¬á€á€²á€· data á€á€½á€±á€¡á€¬á€¸á€œá€¯á€¶á€¸á€€á€­á€¯ á€šá€¬á€šá€®á€™á€¾á€á€ºá€‰á€¬á€á€ºá€‘á€² á€‘á€Šá€·á€ºá€•á€«
                self._search_cache = all_cache
                logger.info(f"Cache {len(all_cache)} á€á€¯á€€á€­á€¯ á€šá€¬á€šá€®á€™á€¾á€á€ºá€‰á€¬á€á€ºá€‘á€²á€á€­á€¯á€· á€¡á€±á€¬á€„á€ºá€™á€¼á€„á€ºá€…á€½á€¬ á€€á€¼á€­á€¯á€–á€¼á€Šá€·á€ºá€•á€¼á€®á€¸á€•á€«á€•á€¼á€®á‹")
            else:
                logger.info("MongoDB á€á€½á€„á€º á€€á€¼á€­á€¯á€á€„á€ºá€–á€¼á€Šá€·á€ºá€›á€”á€º cache á€á€…á€¯á€¶á€á€›á€¬ á€™á€›á€¾á€­á€•á€«á‹")
        except Exception as e:
            logger.error(f"YouTube cache á€€á€¼á€­á€¯á€á€„á€ºá€–á€¼á€Šá€·á€ºá€›á€¬á€á€½á€„á€º á€¡á€™á€¾á€¬á€¸á€–á€¼á€…á€ºá€•á€½á€¬á€¸: {e}")
    # --- (FUNCTION á€¡á€á€…á€º á€’á€®á€™á€¾á€¬á€†á€¯á€¶á€¸) ---


    async def exists(self, link: str, videoid: Union[bool, str] = None):
        if videoid:
            link = self.base + link
        if re.search(self.regex, link):
            return True
        else:
            return False

    async def url(self, message_1: Message) -> Union[str, None]:
        messages = [message_1]
        if message_1.reply_to_message:
            messages.append(message_1.reply_to_message)
        text = ""
        offset = None
        length = None
        for message in messages:
            if offset:
                break
            if message.entities:
                for entity in message.entities:
                    if entity.type == MessageEntityType.URL:
                        text = message.text or message.caption
                        offset, length = entity.offset, entity.length
                        break
            elif message.caption_entities:
                for entity in message.caption_entities:
                    if entity.type == MessageEntityType.TEXT_LINK:
                        return entity.url
        if offset in (None,):
            return None
        return text[offset : offset + length]

    # --- START: Caching Logic Functions (MongoDB á€‘á€Šá€·á€ºá€á€½á€„á€ºá€¸á€‘á€¬á€¸á€á€Šá€º) ---

    async def _fetch_from_youtube(self, link: str):
        """
        YouTube á€€á€­á€¯ á€á€€á€šá€ºá€á€½á€¬á€¸á€›á€¾á€¬á€™á€šá€·á€º private function
        (MongoDB Cache á€á€­á€¯á€· á€á€­á€™á€ºá€¸á€†á€Šá€ºá€¸á€á€¼á€„á€ºá€¸ á€‘á€•á€ºá€á€­á€¯á€¸á€‘á€¬á€¸á€á€Šá€º)
        """
        results = VideosSearch(link, limit=1)
        try:
            result = (await results.next())["result"][0]
        except IndexError:
            logger.error(f"YouTube á€™á€¾á€¬ {link} á€€á€­á€¯ á€›á€¾á€¬á€™á€á€½á€±á€·á€•á€«á‹")
            return None

        title = result["title"]
        duration_min = result["duration"]
        thumbnail = result["thumbnails"][0]["url"].split("?")[0]
        vidid = result["id"]
        yturl = result["link"] # track method á€¡á€á€½á€€á€º link á€€á€­á€¯á€•á€« á€šá€°á€‘á€¬á€¸á€•á€«

        if str(duration_min) == "None":
            duration_sec = 0
        else:
            duration_sec = int(time_to_seconds(duration_min))
            
        # á€¡á€á€»á€€á€ºá€¡á€œá€€á€º á€¡á€…á€¯á€¶á€¡á€œá€„á€ºá€€á€­á€¯ Dictionary á€¡á€–á€¼á€…á€º á€á€Šá€ºá€†á€±á€¬á€€á€ºá€•á€«
        video_details = {
            "title": title,
            "duration_min": duration_min,
            "duration_sec": duration_sec,
            "thumbnail": thumbnail,
            "vidid": vidid,
            "link": yturl, # track method á€¡á€á€½á€€á€º
        }
        
        # --- START: Cache Logic (In-Memory & MongoDB) ---
        
        # 1. In-memory cache á€‘á€²á€€á€­á€¯ vidid á€€á€­á€¯ key á€¡á€”á€±á€”á€²á€· á€á€¯á€¶á€¸á€•á€¼á€®á€¸ á€á€­á€™á€ºá€¸á€‘á€¬á€¸á€•á€«
        self._search_cache[vidid] = video_details
        # 2. In-memory cache á€‘á€²á€€á€­á€¯ Link á€€á€­á€¯ key á€¡á€”á€±á€”á€²á€· á€á€¯á€¶á€¸á€•á€¼á€®á€¸á€œá€Šá€ºá€¸ á€á€­á€™á€ºá€¸á€‘á€¬á€¸á€•á€«
        self._search_cache[link] = video_details
        
        # 3. MongoDB Cache (ytcache_db) á€‘á€²á€€á€­á€¯ vidid á€€á€­á€¯ key á€¡á€”á€±á€”á€²á€· á€á€¯á€¶á€¸á€•á€¼á€®á€¸ á€á€­á€™á€ºá€¸á€•á€«
        await save_yt_cache(vidid, video_details)
        # 4. MongoDB Cache (ytcache_db) á€‘á€²á€€á€­á€¯ Link á€€á€­á€¯ key á€¡á€”á€±á€”á€²á€· á€á€¯á€¶á€¸á€•á€¼á€®á€¸á€œá€Šá€ºá€¸ á€á€­á€™á€ºá€¸á€•á€«
        await save_yt_cache(link, video_details)
        
        logger.info(f"Saved Search Result to MongoDB Cache: {vidid} / {link}")
        
        # --- END: Cache Logic ---
        
        return video_details

    async def _get_video_details(self, link: str, videoid: Union[bool, str] = None):
        """
        á€¡á€á€»á€€á€ºá€¡á€œá€€á€º á€œá€­á€¯á€¡á€•á€ºá€á€­á€¯á€„á€ºá€¸ á€’á€® function á€€á€­á€¯ á€á€±á€«á€ºá€á€¯á€¶á€¸á€•á€«á€™á€šá€ºá‹
        á€’á€«á€€ Cache á€€á€­á€¯ á€¡á€›á€„á€ºá€…á€…á€ºá€•á€«á€™á€šá€ºá‹ (In-Memory + MongoDB)
        """
        if videoid:
            link = self.base + link
        if "&" in link:
            link = link.split("&")[0]

        # 1. Cache Key á€€á€­á€¯ á€á€á€ºá€™á€¾á€á€ºá€•á€« (link á€€á€­á€¯ key á€¡á€–á€¼á€…á€º á€á€¯á€¶á€¸á€•á€«á€™á€Šá€º)
        cache_key = link

        # 2. á€šá€¬á€šá€®á€™á€¾á€á€ºá€‰á€¬á€á€º (Pre-load á€œá€¯á€•á€ºá€‘á€¬á€¸á€á€²á€·) á€‘á€²á€™á€¾á€¬ á€¡á€›á€„á€ºá€›á€¾á€¬á€•á€«
        if cache_key in self._search_cache:
            logger.info(f"Cache Hit (Memory): {cache_key}")
            return self._search_cache[cache_key]
            
        # 3. á€šá€¬á€šá€®á€‘á€²á€™á€¾á€¬ á€™á€›á€¾á€­á€™á€¾ MongoDB (á€¡á€™á€¼á€²á€á€™á€ºá€¸ á€™á€¾á€á€ºá€‰á€¬á€á€º) á€‘á€²á€™á€¾á€¬ á€›á€¾á€¬á€€á€¼á€Šá€·á€ºá€•á€«
        mongo_details = await get_yt_cache(cache_key)
        if mongo_details:
            logger.info(f"Cache Hit (MongoDB): {cache_key}")
            # MongoDB á€™á€¾á€¬á€á€½á€±á€·á€›á€„á€º In-Memory cache á€‘á€²á€€á€­á€¯ á€•á€¼á€”á€ºá€‘á€Šá€·á€ºá€•á€«
            self._search_cache[cache_key] = mongo_details
            if mongo_details.get("vidid"):
                self._search_cache[mongo_details["vidid"]] = mongo_details  # <-- Error 4: IndentationError á€€á€­á€¯ á€•á€¼á€„á€ºá€‘á€¬á€¸á€á€Šá€º
            return mongo_details
            
        # 4. Cache á€‘á€²á€™á€¾á€¬á€™á€›á€¾á€­á€›á€„á€º YouTube á€€á€­á€¯ á€á€€á€šá€ºá€á€½á€¬á€¸á€›á€¾á€¬á€•á€«
        logger.info(f"Cache Miss. Fetching from YouTube: {cache_key}")
        details = await self._fetch_from_youtube(link)
        
        # 5. _fetch_from_youtube á€€ cache á€‘á€² á€á€­á€™á€ºá€¸á€•á€¼á€®á€¸á€á€¬á€¸á€–á€¼á€…á€ºá€•á€«á€™á€Šá€º
        
        return details

    # --- END: Caching Logic Functions ---


    # --- START: Caching á€€á€­á€¯ á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€‘á€¬á€¸á€á€±á€¬ Functions á€™á€»á€¬á€¸ (á€™á€°á€œá€¡á€á€­á€¯á€„á€ºá€¸) ---

    async def details(self, link: str, videoid: Union[bool, str] = None):
        details = await self._get_video_details(link, videoid)
        if not details:
            return None, None, 0, None, None
            
        return (
            details["title"],
            details["duration_min"],
            details["duration_sec"],
            details["thumbnail"],
            details["vidid"],
        )

    async def title(self, link: str, videoid: Union[bool, str] = None):
        details = await self._get_video_details(link, videoid)
        return details["title"] if details else "Unknown Title"

    async def duration(self, link: str, videoid: Union[bool, str] = None):
        details = await self._get_video_details(link, videoid)
        return details["duration_min"] if details else "00:00"

    async def thumbnail(self, link: str, videoid: Union[bool, str] = None):
        details = await self._get_video_details(link, videoid)
        return details["thumbnail"] if details else None

    async def track(self, link: str, videoid: Union[bool, str] = None):
        details = await self._get_video_details(link, videoid)
        if not details:
            return {}, None
            
        track_details = {
            "title": details["title"],
            "link": details["link"],
            "vidid": details["vidid"],
            "duration_min": details["duration_min"],
            "thumb": details["thumbnail"],
        }
        return track_details, details["vidid"]

    # --- END: Caching á€€á€­á€¯ á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€‘á€¬á€¸á€á€±á€¬ Functions á€™á€»á€¬á€¸ ---

    # --- START: Live Stream á€¡á€á€½á€€á€º Function (á€’á€«á€€á€­á€¯á€•á€« á€•á€¼á€„á€ºá€›á€•á€«á€™á€šá€º) ---

    async def video(self, link: str, videoid: Union[bool, str] = None):
        if videoid:
            link = self.base + link
        if "&" in link:
            link = link.split("&")[0]
            
        cookie_file = get_cookies() # <-- Cookie á€€á€­á€¯á€•á€« á€á€¯á€¶á€¸á€•á€«
        proc_args = [
            "yt-dlp",
            "-g",
            "-f",
            # --- (Live Stream á€™á€¾á€¬á€œá€Šá€ºá€¸ á€¡á€á€¶á€•á€«á€¡á€±á€¬á€„á€º á€•á€¼á€„á€ºá€†á€„á€ºá€‘á€¬á€¸á€á€Šá€º) ---
            "best[height<=?720][acodec!=none]/best[height<=?720]",
        ]
        if cookie_file:
            proc_args.extend(["--cookies", cookie_file])
        proc_args.append(link)
            
        proc = await asyncio.create_subprocess_exec(
            *proc_args,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )
        stdout, stderr = await proc.communicate()
        if stdout:
            return 1, stdout.decode().split("\n")[0]
        else:
            return 0, stderr.decode()

    async def playlist(self, link, limit, user_id, videoid: Union[bool, str] = None):
        if videoid:
            link = self.listbase + link
        if "&" in link:
            link = link.split("&")[0]
        playlist = await shell_cmd(
            f"yt-dlp -i --get-id --flat-playlist --playlist-end {limit} --skip-download {link}"
        )
        try:
            result = playlist.split("\n")
            for key in result:
                if key == "":
                    result.remove(key)
        except:
            result = []
        return result

    async def formats(self, link: str, videoid: Union[bool, str] = None):
        if videoid:
            link = self.base + link
        if "&" in link:
            link = link.split("&")[0]
        ytdl_opts = { "quiet": True } 
        ydl = yt_dlp.YoutubeDL(ytdl_opts)
        with ydl:
            formats_available = []
            r = ydl.extract_info(link, download=False)
            for format in r["formats"]:
                try:
                    str(format["format"])
                except:
                    continue
                if not "dash" in str(format["format"]).lower():
                    try:
                        format["format"]
                        format["filesize"]
                        format["format_id"]
                        format["ext"]
                        format["format_note"]
                    except:
                        continue
                    formats_available.append(
                        {
                            "format": format["format"],
                            "filesize": format["filesize"],
                            "format_id": format["format_id"],
                            "ext": format["ext"],
                            "format_note": format["format_note"],
                            "yturl": link,
                        }
                    )
            return formats_available, link

    async def slider(
        self,
        link: str,
        query_type: int,
        videoid: Union[bool, str] = None,
    ):
        if videoid:
            link = self.base + link
        if "&" in link:
            link = link.split("&")[0]
        a = VideosSearch(link, limit=10)
        result = (await a.next()).get("result")
        title = result[query_type]["title"]
        duration_min = result[query_type]["duration"]
        vidid = result[query_type]["id"]
        thumbnail = result[query_type]["thumbnails"][0]["url"].split("?")[0]
        return title, duration_min, thumbnail, vidid

    # --- END: á€™á€°á€œ Functions á€™á€»á€¬á€¸ ---
    
    # --- START: FAST JOIN (2-SECOND) MODIFICATION ---
    # --- á€’á€® 'download' function á€á€…á€ºá€á€¯á€œá€¯á€¶á€¸á€€á€­á€¯ á€¡á€á€…á€º á€œá€²á€‘á€Šá€·á€ºá€•á€« ---
    
    async def download(
        self,
        link: str,
        mystic,
        video: Union[bool, str] = None,
        videoid: Union[bool, str] = None,
        songaudio: Union[bool, str] = None,
        songvideo: Union[bool, str] = None,
        format_id: Union[bool, str] = None,
        title: Union[bool, str] = None,
    ) -> tuple[str, bool]:
        if videoid:
            link = self.base + link
        loop = asyncio.get_running_loop()
        cookie_file = get_cookies()

        # --- (Slow Download) Fallback Functions ---
        def audio_dl_fallback():
            """Slow Download (Fallback) for Audio"""
            ydl_optssx = {
                "format": "bestaudio[ext=m4a]/bestaudio/best",
                "outtmpl": "downloads/%(id)s.%(ext)s",
                "geo_bypass": True,
                "nocheckcertificate": True,
                "quiet": True,
                "no_warnings": True,
            }
            if cookie_file:
                ydl_optssx["cookiefile"] = cookie_file
            x = yt_dlp.YoutubeDL(ydl_optssx)
            info = x.extract_info(link, False)
            xyz = os.path.join("downloads", f"{info['id']}.{info['ext']}")
            if not os.path.exists(xyz):
                x.download([link])
            return xyz

        def video_dl_fallback():
            """Slow Download (Fallback) for Video"""
            ydl_optssx = {
                "format": "bestvideo[height<=?720][width<=?1280]+bestaudio/best[height<=?720][width<=?1280]",
                "outtmpl": "downloads/%(id)s.%(ext)s",
                "geo_bypass": True,
                "nocheckcertificate": True,
                "quiet": True,
                "no_warnings": True,
                "prefer_ffmpeg": True,
                "merge_output_format": "mp4",
            }
            if cookie_file:
                ydl_optssx["cookiefile"] = cookie_file
            x = yt_dlp.YoutubeDL(ydl_optssx)
            info = x.extract_info(link, False)
            xyz = os.path.join("downloads", f"{info['id']}.mp4")
            if not os.path.exists(xyz):
                x.download([link])
            return xyz
        
        # --- (songaudio/songvideo - à¦à¦—à§à¦²à§‹à¦•à§‡ fast join à¦à¦° à¦¦à¦°à¦•à¦¾à¦° à¦¨à§‡à¦‡) ---
        if songvideo:
            # This part is for /song command, not /play or /vplay
            # It needs to download, so we use the original logic (but fixed)
            def song_video_dl():
                formats = f"{format_id}+140"
                fpath = f"downloads/{title}"
                ydl_optssx = {"format": formats, "outtmpl": fpath, "geo_bypass": True, "nocheckcertificate": True, "quiet": True, "no_warnings": True, "prefer_ffmpeg": True, "merge_output_format": "mp4"}
                if cookie_file: ydl_optssx["cookiefile"] = cookie_file
                x = yt_dlp.YoutubeDL(ydl_optssx); x.download([link])
            await loop.run_in_executor(None, song_video_dl)
            fpath = f"downloads/{title}.mp4"
            return fpath, True  # Return as (filepath, direct=True)
            
        elif songaudio:
            # This part is for /song command, not /play or /vplay
            def song_audio_dl():
                fpath = f"downloads/{title}.%(ext)s"
                ydl_optssx = {"format": format_id, "outtmpl": fpath, "geo_bypass": True, "nocheckcertificate": True, "quiet": True, "no_warnings": True, "prefer_ffmpeg": True, "postprocessors": [{"key": "FFmpegExtractAudio", "preferredcodec": "mp3", "preferredquality": "320"}]}
                if cookie_file: ydl_optssx["cookiefile"] = cookie_file
                x = yt_dlp.YoutubeDL(ydl_optssx); x.download([link])
            await loop.run_in_executor(None, song_audio_dl)
            fpath = f"downloads/{title}.mp3"
            return fpath, True # Return as (filepath, direct=True)

        # --- (Fast Join) Logic for /play and /vplay ---
        
        # 'is_on_off(1)' check á€€á€­á€¯ 'if False:' á€œá€­á€¯á€· á€•á€¼á€±á€¬á€„á€ºá€¸á€•á€¼á€®á€¸ stream mode á€€á€­á€¯ force á€œá€¯á€•á€ºá€•á€«
        # á€’á€«á€€ slow download (video_dl/audio_dl) á€€á€­á€¯ á€œá€¯á€¶á€¸á€ á€™á€á€±á€«á€ºá€á€±á€¬á€·á€•á€«á€˜á€°á€¸
        if await is_on_off(1) and not video: # API/DB Cache logic only for AUDIO
             # --- START: API Logic (DB File Path Cache á€–á€¼á€„á€·á€º) ---
            downloaded_file = None
            direct = True  # API or audio_dl will be a direct file path
            video_id = None # video_id á€€á€­á€¯ á€¡á€…á€•á€¼á€¯á€‘á€¬á€¸á€•á€«

            try:
                video_id = extract_video_id(link)
                cached_path = await get_cached_song_path(video_id)
                if cached_path:
                    if os.path.exists(cached_path):
                        logger.info(f"DB Cache Hit (File Exists): {cached_path}")
                        downloaded_file = cached_path
                        return downloaded_file, direct # á€á€»á€€á€ºá€á€»á€„á€ºá€¸á€•á€¼á€”á€ºá€•á€±á€¸á€œá€­á€¯á€€á€ºá€•á€«
                    else:
                        logger.warning(f"DB Cache Stale (File Missing): {cached_path}. Removing entry.")
                        await remove_cached_song_path(video_id)
                
                logger.info(f"DB Cache Miss. Attempting API download for {video_id}...")
                downloaded_file = await loop.run_in_executor(None, api_dl, video_id)

            except ValueError as e:
                logger.warning(f"Could not extract video ID for API download: {e}")
                downloaded_file = None
            except Exception as e:
                logger.error(f"An error occurred during API download attempt: {e}")
                downloaded_file = None

            if not downloaded_file:
                logger.warning(f"API download failed for {link}. Falling back to yt-dlp (cookies)...")
                downloaded_file = await loop.run_in_executor(None, audio_dl_fallback)
            else:
                logger.info(f"API download successful: {downloaded_file}")
                
            if downloaded_file and video_id:
                await save_cached_song_path(video_id, downloaded_file)
            elif downloaded_file and not video_id:
                try:
                    vid_from_path = os.path.basename(downloaded_file).split('.')[0]
                    if len(vid_from_path) == 11:
                        await save_cached_song_path(vid_from_path, downloaded_file)
                except Exception as e:
                    logger.error(f"Could not save fallback path to DB: {e}")
            
            return downloaded_file, direct
            
        else:
            # --- This is the FAST JOIN (2-Second) part ---
            if video:
                logger.info(f"Fast Join (Video) requested for: {link}")
                # --- (START: á€¡á€á€¶á€™á€•á€«á€á€²á€· á€•á€¼á€¿á€”á€¬á€€á€­á€¯ á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€›á€”á€º) ---
                # "bestvideo+bestaudio" (á€¡á€á€¶á€™á€•á€«) á€¡á€…á€¬á€¸ "á€›á€¯á€•á€ºá€›á€±á€¬á€á€¶á€›á€±á€¬á€•á€«á€á€²á€·" format á€€á€­á€¯ á€á€±á€¬á€„á€ºá€¸á€•á€«
                format = "best[height<=?720][acodec!=none]/best[ext=mp4][height<=?720]/best[height<=?720]"
                # --- (END: á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€›á€”á€º) ---
                fallback_func = video_dl_fallback
            else:
                logger.info(f"Fast Join (Audio) requested for: {link}")
                format = "bestaudio[ext=m4a]/bestaudio/best"
                fallback_func = audio_dl_fallback

            proc_args = ["yt-dlp", "-g", "-f", format]
            if cookie_file:
                proc_args.extend(["--cookies", cookie_file])
            proc_args.append(link)

            proc = await asyncio.create_subprocess_exec(
                *proc_args,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
            )
            stdout, stderr = await proc.communicate()
            
            if stdout:
                stream_link = stdout.decode().split("\n")[0]
                logger.info(f"Fast Join (Stream Link) found: {stream_link[:50]}...")
                return stream_link, False  # Return (URL, direct=False)
            else:
                logger.warning(f"FAST STREAM á€™á€›á€•á€« ({'Video' if video else 'Audio'})á‹ SLOW DOWNLOAD á€á€­á€¯á€· Fallback á€œá€¯á€•á€ºá€”á€±á€•á€«á€á€Šá€º: {stderr.decode()}")
                downloaded_file = await loop.run_in_executor(None, fallback_func)
                return downloaded_file, True # Return (Local File Path, direct=True)
